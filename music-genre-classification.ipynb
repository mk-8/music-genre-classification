{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries we would be working on\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "\n",
    "# Librosa - The god of audio files\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_of_dataset = \"C:/Users/Dell Laptop/Downloads/dt2/Data\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(f'{path_of_dataset}/genres_original/rock/rock.00046.wav')\n",
    "\n",
    "print('y:', y, '\\n')\n",
    "print('y shape:', np.shape(y), '\\n')\n",
    "print('Sample Rate (KHz):', sr, '\\n')\n",
    "\n",
    "#length of the audio\n",
    "print('Check Len of Audio:', 661794/22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trimming silence from an audio signal\n",
    "audio_file, _ = librosa.effects.trim(y)\n",
    "\n",
    "# the result is an numpy ndarray\n",
    "print('Audio File:', audio_file, '\\n')\n",
    "print('Audio File shape:', np.shape(audio_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D representation of sound waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 6))\n",
    "librosa.display.waveshow(y = audio_file, sr = sr, color = \"Blue\");\n",
    "plt.title(\"Sound Waves in Rock 46\", fontsize = 23);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 2048 # window size\n",
    "hop_length = 512 # number audio of frames between STFT columns\n",
    "\n",
    "# Short-time Fourier transform (STFT)\n",
    "D = np.abs(librosa.stft(audio_file, n_fft = n_fft, hop_length = hop_length))\n",
    "\n",
    "print('Shape of D object:', np.shape(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 6))\n",
    "plt.plot(D);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert an amplitude spectrogram to Decibels-scaled spectrogram.\n",
    "DB = librosa.amplitude_to_db(D, ref = np.max)\n",
    "\n",
    "# Creating the Spectogram\n",
    "plt.figure(figsize = (16, 6))\n",
    "librosa.display.specshow(DB, sr = sr, hop_length = hop_length, x_axis = 'time', y_axis = 'log',\n",
    "                        cmap = 'cool')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mel Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(f'{path_of_dataset}/genres_original/pop/pop.00046.wav')\n",
    "y, _ = librosa.effects.trim(y)\n",
    "\n",
    "\n",
    "S = librosa.feature.melspectrogram(y, sr=sr)\n",
    "S_DB = librosa.amplitude_to_db(S, ref=np.max)\n",
    "plt.figure(figsize = (16, 6))\n",
    "librosa.display.specshow(S_DB, sr=sr, hop_length=hop_length, x_axis = 'time', y_axis = 'log',\n",
    "                        cmap = 'cool');\n",
    "plt.colorbar();\n",
    "plt.title(\"POP Mel Spectrogram\", fontsize = 23);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(f'{path_of_dataset}/genres_original/classical/classical.00046.wav')\n",
    "y, _ = librosa.effects.trim(y)\n",
    "\n",
    "\n",
    "S = librosa.feature.melspectrogram(y, sr=sr)\n",
    "S_DB = librosa.amplitude_to_db(S, ref=np.max)\n",
    "plt.figure(figsize = (16, 6))\n",
    "librosa.display.specshow(S_DB, sr=sr, hop_length=hop_length, x_axis = 'time', y_axis = 'log',\n",
    "                        cmap = 'cool');\n",
    "plt.colorbar();\n",
    "plt.title(\"Classical Mel Spectrogram\", fontsize = 23);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zero Crossing Rate - the rate at which the signal changes from positive to negative of back\n",
    "zero_crossings = librosa.zero_crossings(audio_file, pad=False)\n",
    "print(sum(zero_crossings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Harmonics and Perceptual - Harmonics are characteristics that human years can't distinguish, Perceptual understanding shock wave represents the sound rhythm and emotion\n",
    "y_harm, y_perc = librosa.effects.hpss(audio_file)\n",
    "\n",
    "plt.figure(figsize = (16, 6))\n",
    "plt.plot(y_harm, color = 'Black');\n",
    "plt.plot(y_perc, color = 'Orange');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tempo BMP  - Dynamic programming beat tracker.\n",
    "tempo, _ = librosa.beat.beat_track(y, sr = sr)\n",
    "tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specral Centroid - The center of mass of the spectrum\n",
    "spectral_centroids = librosa.feature.spectral_centroid(audio_file, sr=sr)[0]\n",
    "\n",
    "# Shape is a vector\n",
    "print('Centroids:', spectral_centroids, '\\n')\n",
    "print('Shape of Spectral Centroids:', spectral_centroids.shape, '\\n')\n",
    "\n",
    "# Computing the time variable for visualization\n",
    "frames = range(len(spectral_centroids))\n",
    "\n",
    "# Converts frame counts to time (seconds)\n",
    "t = librosa.frames_to_time(frames)\n",
    "\n",
    "print('frames:', frames, '\\n')\n",
    "print('t:', t)\n",
    "\n",
    "# Function that normalizes the Sound Data\n",
    "def normalize(x, axis=0):\n",
    "    return sklearn.preprocessing.minmax_scale(x, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the Spectral Centroid along the waveform\n",
    "plt.figure(figsize = (16, 6))\n",
    "librosa.display.waveshow(audio_file, sr=sr, alpha=0.4, color = 'Black');\n",
    "plt.plot(t, normalize(spectral_centroids), color='Orange');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral RollOff Vector\n",
    "spectral_rolloff = librosa.feature.spectral_rolloff(audio_file, sr=sr)[0]\n",
    "\n",
    "# The plot\n",
    "plt.figure(figsize = (16, 6))\n",
    "librosa.display.waveshow(audio_file, sr=sr, alpha=0.4, color = 'Black');\n",
    "plt.plot(t, normalize(spectral_rolloff), color='Orange');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mel-Frequency Cepstral Coefficients (MFCCs)\n",
    "mfccs = librosa.feature.mfcc(audio_file, sr=sr)\n",
    "print('mfccs shape:', mfccs.shape)\n",
    "\n",
    "#Displaying  the MFCCs:\n",
    "plt.figure(figsize = (16, 6))\n",
    "librosa.display.specshow(mfccs, sr=sr, x_axis='time', cmap = 'cool');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Feature Scaling\n",
    "mfccs = sklearn.preprocessing.scale(mfccs, axis=1)\n",
    "print('Mean:', mfccs.mean(), '\\n')\n",
    "print('Var:', mfccs.var())\n",
    "\n",
    "plt.figure(figsize = (16, 6))\n",
    "librosa.display.specshow(mfccs, sr=sr, x_axis='time', cmap = 'cool');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chroma Frequencies\n",
    "# Increase or decrease hop_length to change how granular you want your data to be\n",
    "hop_length = 5000\n",
    "\n",
    "# Chromogram\n",
    "chromagram = librosa.feature.chroma_stft(audio_file, sr=sr, hop_length=hop_length)\n",
    "print('Chromogram shape:', chromagram.shape)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=hop_length, cmap='coolwarm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA - Exploratory Data Analysis\n",
    "data = pd.read_csv(f'{path_of_dataset}/features_30_sec.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the Correlation Matrix\n",
    "spike_cols = [col for col in data.columns if 'mean' in col]\n",
    "corr = data[spike_cols].corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(16, 11));\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(0, 25, as_cmap=True, s = 90, l = 45, n = 5)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "plt.title('Correlation Heatmap (for the MEAN variables)', fontsize = 25)\n",
    "plt.xticks(fontsize = 10)\n",
    "plt.yticks(fontsize = 10);\n",
    "plt.savefig(\"Corr Heatmap.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[[\"label\", \"tempo\"]]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 9));\n",
    "sns.boxplot(x = \"label\", y = \"tempo\", data = x, palette = 'husl');\n",
    "\n",
    "plt.title('BPM Boxplot for Genres', fontsize = 25)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 10);\n",
    "plt.xlabel(\"Genre\", fontsize = 15)\n",
    "plt.ylabel(\"BPM\", fontsize = 15)\n",
    "plt.savefig(\"BPM Boxplot.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "data = data.iloc[0:, 1:]\n",
    "y = data['label']\n",
    "X = data.loc[:, data.columns != 'label']\n",
    "\n",
    "#NORMALIZE X \n",
    "cols = X.columns\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(X)\n",
    "X = pd.DataFrame(np_scaled, columns = cols)\n",
    "\n",
    "\n",
    "#PCA 2 COMPONENTS \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "# concatenate with target label\n",
    "finalDf = pd.concat([principalDf, y], axis = 1)\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 9))\n",
    "sns.scatterplot(x = \"principal component 1\", y = \"principal component 2\", data = finalDf, hue = \"label\", alpha = 0.7,\n",
    "               s = 100);\n",
    "\n",
    "plt.title('PCA on Genres', fontsize = 25)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 10);\n",
    "plt.xlabel(\"Principal Component 1\", fontsize = 15)\n",
    "plt.ylabel(\"Principal Component 2\", fontsize = 15)\n",
    "plt.savefig(\"PCA Scattert.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from xgboost import plot_tree, plot_importance\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'{path_of_dataset}/features_3_sec.csv')\n",
    "data = data.iloc[0:, 1:] \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['label'] # genre variable.\n",
    "X = data.loc[:, data.columns != 'label'] #select all columns but not the labels\n",
    "\n",
    "# NORMALIZE X\n",
    "\n",
    "# Normalize so everything is on the same scale. \n",
    "\n",
    "cols = X.columns\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# new data frame with the new scaled data. \n",
    "X = pd.DataFrame(np_scaled, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_assess(model, title = \"Default\"):\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    #print(confusion_matrix(y_test, preds))\n",
    "    print('Accuracy', title, ':', round(accuracy_score(y_test, preds), 5), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Neural Nets : 0.67267 \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6 7 8 9], got ['blues' 'classical' 'country' 'disco' 'hiphop' 'jazz' 'metal' 'pop'\n 'reggae' 'rock']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [43], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39m# Cross Gradient Booster\u001b[39;00m\n\u001b[0;32m     34\u001b[0m xgb \u001b[39m=\u001b[39m XGBClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m model_assess(xgb, \u001b[39m\"\u001b[39;49m\u001b[39mCross Gradient Booster\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     37\u001b[0m \u001b[39m# Cross Gradient Booster (Random Forest)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m xgbrf \u001b[39m=\u001b[39m XGBRFClassifier(objective\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmulti:softmax\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [42], line 2\u001b[0m, in \u001b[0;36mmodel_assess\u001b[1;34m(model, title)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel_assess\u001b[39m(model, title \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDefault\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      3\u001b[0m     preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      4\u001b[0m     \u001b[39m#print(confusion_matrix(y_test, preds))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell Laptop\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    574\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 575\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Dell Laptop\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1357\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1352\u001b[0m     expected_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_)\n\u001b[0;32m   1353\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1354\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m expected_classes\u001b[39m.\u001b[39mshape\n\u001b[0;32m   1355\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m==\u001b[39m expected_classes)\u001b[39m.\u001b[39mall()\n\u001b[0;32m   1356\u001b[0m ):\n\u001b[1;32m-> 1357\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1358\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1359\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected: \u001b[39m\u001b[39m{\u001b[39;00mexpected_classes\u001b[39m}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1360\u001b[0m     )\n\u001b[0;32m   1362\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1364\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6 7 8 9], got ['blues' 'classical' 'country' 'disco' 'hiphop' 'jazz' 'metal' 'pop'\n 'reggae' 'rock']"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "model_assess(nb, \"Naive Bayes\")\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "sgd = SGDClassifier(max_iter=5000, random_state=0)\n",
    "model_assess(sgd, \"Stochastic Gradient Descent\")\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=19)\n",
    "model_assess(knn, \"KNN\")\n",
    "\n",
    "# Decission trees\n",
    "tree = DecisionTreeClassifier()\n",
    "model_assess(tree, \"Decission trees\")\n",
    "\n",
    "# Random Forest\n",
    "rforest = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0)\n",
    "model_assess(rforest, \"Random Forest\")\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC(decision_function_shape=\"ovo\")\n",
    "model_assess(svm, \"Support Vector Machine\")\n",
    "\n",
    "# Logistic Regression\n",
    "lg = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "model_assess(lg, \"Logistic Regression\")\n",
    "\n",
    "# Neural Nets\n",
    "nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5000, 10), random_state=1)\n",
    "model_assess(nn, \"Neural Nets\")\n",
    "\n",
    "# Cross Gradient Booster\n",
    "xgb = XGBClassifier(n_estimators=1000, learning_rate=0.05)\n",
    "model_assess(xgb, \"Cross Gradient Booster\")\n",
    "\n",
    "# Cross Gradient Booster (Random Forest)\n",
    "xgbrf = XGBRFClassifier(objective= 'multi:softmax')\n",
    "model_assess(xgbrf, \"Cross Gradient Booster (Random Forest)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model\n",
    "xgb = XGBClassifier(n_estimators=1000, learning_rate=0.05)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "preds = xgb.predict(X_test)\n",
    "\n",
    "print('Accuracy', ':', round(accuracy_score(y_test, preds), 5), '\\n')\n",
    "\n",
    "# Confusion Matrix\n",
    "confusion_matr = confusion_matrix(y_test, preds) #normalize = 'true'\n",
    "plt.figure(figsize = (16, 9))\n",
    "sns.heatmap(confusion_matr, cmap=\"Blues\", annot=True, \n",
    "            xticklabels = [\"blues\", \"classical\", \"country\", \"disco\", \"hiphop\", \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"],\n",
    "           yticklabels=[\"blues\", \"classical\", \"country\", \"disco\", \"hiphop\", \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"]);\n",
    "plt.savefig(\"conf matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(estimator=xgb, random_state=1)\n",
    "perm.fit(X_test, y_test)\n",
    "\n",
    "eli5.show_weights(estimator=perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import IPython.display as ipd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv(f'{general_path}/features_30_sec.csv', index_col='filename')\n",
    "\n",
    "# Extract labels\n",
    "labels = data[['label']]\n",
    "\n",
    "# Drop labels from original dataframe\n",
    "data = data.drop(columns=['length','label'])\n",
    "data.head()\n",
    "\n",
    "# Scale the data\n",
    "data_scaled=preprocessing.scale(data)\n",
    "print('Scaled data type:', type(data_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity\n",
    "similarity = cosine_similarity(data_scaled)\n",
    "print(\"Similarity shape:\", similarity.shape)\n",
    "\n",
    "# Convert into a dataframe and then set the row index and column names as labels\n",
    "sim_df_labels = pd.DataFrame(similarity)\n",
    "sim_df_names = sim_df_labels.set_index(labels.index)\n",
    "sim_df_names.columns = labels.index\n",
    "\n",
    "sim_df_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_songs(name):\n",
    "    # Find songs most similar to another song\n",
    "    series = sim_df_names[name].sort_values(ascending = False)\n",
    "    \n",
    "    # Remove cosine similarity == 1 (songs will always have the best match with themselves)\n",
    "    series = series.drop(name)\n",
    "    \n",
    "    # Display the 5 top matches \n",
    "    print(\"\\n*******\\nSimilar songs to \", name)\n",
    "    print(series.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop.00019 - Britney Spears \"Hit me baby one more time\"\n",
    "find_similar_songs('pop.00019.wav') \n",
    "\n",
    "ipd.Audio(f'{general_path}/genres_original/pop/pop.00019.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(f'{general_path}/genres_original/pop/pop.00023.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(f'{general_path}/genres_original/pop/pop.00034.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(f'{general_path}/genres_original/pop/pop.00078.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(f'{general_path}/genres_original/pop/pop.00088.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(f'{general_path}/genres_original/pop/pop.00091.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_similar_songs('metal.00002.wav') \n",
    "\n",
    "ipd.Audio(f'{general_path}/genres_original/metal/metal.00002.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(f'{general_path}/genres_original/metal/metal.00028.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(f'{general_path}/genres_original/metal/metal.00059.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(f'{general_path}/genres_original/rock/rock.00018.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(f'{general_path}/genres_original/rock/rock.00017.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(f'{general_path}/genres_original/rock/rock.00016.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a64c07eda29cd4ca4289b4c4a285218cd30fe3182897b00becef48cf9382d08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
